{
  "access_type": "PRIVATE",
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-SnUTy",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-kD8Fx",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-SnUTy{œdataTypeœ:œChatInputœ,œidœ:œChatInput-SnUTyœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-kD8Fx{œfieldNameœ:œquestionœ,œidœ:œPrompt-kD8Fxœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-SnUTy",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-SnUTyœ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Prompt-kD8Fx",
        "targetHandle": "{œfieldNameœ: œquestionœ, œidœ: œPrompt-kD8Fxœ, œinputTypesœ: [œMessageœ, œTextœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "parser",
            "id": "parser-VFDaF",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-kD8Fx",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-parser-VFDaF{œdataTypeœ:œparserœ,œidœ:œparser-VFDaFœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-kD8Fx{œfieldNameœ:œcontextœ,œidœ:œPrompt-kD8Fxœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "parser-VFDaF",
        "sourceHandle": "{œdataTypeœ: œparserœ, œidœ: œparser-VFDaFœ, œnameœ: œparsed_textœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Prompt-kD8Fx",
        "targetHandle": "{œfieldNameœ: œcontextœ, œidœ: œPrompt-kD8Fxœ, œinputTypesœ: [œMessageœ, œTextœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "File",
            "id": "File-ANot7",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-fCJsK",
            "inputTypes": [
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__File-ANot7{œdataTypeœ:œFileœ,œidœ:œFile-ANot7œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-fCJsK{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-fCJsKœ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "File-ANot7",
        "sourceHandle": "{œdataTypeœ: œFileœ, œidœ: œFile-ANot7œ, œnameœ: œdataœ, œoutput_typesœ: [œDataœ]}",
        "target": "SplitText-fCJsK",
        "targetHandle": "{œfieldNameœ: œdata_inputsœ, œidœ: œSplitText-fCJsKœ, œinputTypesœ: [œDataœ, œDataFrameœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-kD8Fx",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "NearAIModel-nDRyQ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-kD8Fx{œdataTypeœ:œPromptœ,œidœ:œPrompt-kD8Fxœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-NearAIModel-nDRyQ{œfieldNameœ:œinput_valueœ,œidœ:œNearAIModel-nDRyQœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-kD8Fx",
        "sourceHandle": "{œdataTypeœ: œPromptœ, œidœ: œPrompt-kD8Fxœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "NearAIModel-nDRyQ",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œNearAIModel-nDRyQœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "NearAIModel",
            "id": "NearAIModel-nDRyQ",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Srsio",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__NearAIModel-nDRyQ{œdataTypeœ:œNearAIModelœ,œidœ:œNearAIModel-nDRyQœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Srsio{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Srsioœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "NearAIModel-nDRyQ",
        "sourceHandle": "{œdataTypeœ: œNearAIModelœ, œidœ: œNearAIModel-nDRyQœ, œnameœ: œtext_outputœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ChatOutput-Srsio",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œChatOutput-Srsioœ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-fCJsK",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "NearVectorDB-m7loS",
            "inputTypes": [
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__SplitText-fCJsK{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-fCJsKœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}-NearVectorDB-m7loS{œfieldNameœ:œingest_dataœ,œidœ:œNearVectorDB-m7loSœ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitText-fCJsK",
        "sourceHandle": "{œdataTypeœ: œSplitTextœ, œidœ: œSplitText-fCJsKœ, œnameœ: œchunksœ, œoutput_typesœ: [œDataœ]}",
        "target": "NearVectorDB-m7loS",
        "targetHandle": "{œfieldNameœ: œingest_dataœ, œidœ: œNearVectorDB-m7loSœ, œinputTypesœ: [œDataœ, œDataFrameœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-SnUTy",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "NearVectorDB-eKQKI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-SnUTy{œdataTypeœ:œChatInputœ,œidœ:œChatInput-SnUTyœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-NearVectorDB-eKQKI{œfieldNameœ:œsearch_queryœ,œidœ:œNearVectorDB-eKQKIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-SnUTy",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-SnUTyœ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "NearVectorDB-eKQKI",
        "targetHandle": "{œfieldNameœ: œsearch_queryœ, œidœ: œNearVectorDB-eKQKIœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "NearVectorDB",
            "id": "NearVectorDB-eKQKI",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "parser-VFDaF",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__NearVectorDB-eKQKI{œdataTypeœ:œNearVectorDBœ,œidœ:œNearVectorDB-eKQKIœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-parser-VFDaF{œfieldNameœ:œinput_dataœ,œidœ:œparser-VFDaFœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "NearVectorDB-eKQKI",
        "sourceHandle": "{œdataTypeœ: œNearVectorDBœ, œidœ: œNearVectorDB-eKQKIœ, œnameœ: œsearch_resultsœ, œoutput_typesœ: [œDataœ]}",
        "target": "parser-VFDaF",
        "targetHandle": "{œfieldNameœ: œinput_dataœ, œidœ: œparser-VFDaFœ, œinputTypesœ: [œDataFrameœ, œDataœ], œtypeœ: œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-SnUTy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "What is the document is about?"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatInput-SnUTy",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 489.8452082997858,
          "y": 1363.66004510605
        },
        "positionAbsolute": {
          "x": 743.9745420290319,
          "y": 463.6977510207854
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-kD8Fx",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "context",
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "context": {
                "advanced": false,
                "display_name": "context",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "context",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "{context}\n\n---\n\nGiven the context above, answer the question as best as possible.\n\nQuestion: {question}\n\nAnswer: "
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 433,
        "id": "Prompt-kD8Fx",
        "measured": {
          "height": 433,
          "width": 320
        },
        "position": {
          "x": 1565.5658766024656,
          "y": 1370.0216801219358
        },
        "positionAbsolute": {
          "x": 1977.9097981422992,
          "y": 640.5656416923846
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Split text into chunks based on specified criteria.",
          "display_name": "Split Text",
          "id": "SplitText-fCJsK",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "frozen": false,
            "icon": "scissors-line-dashed",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "method": "split_text",
                "name": "chunks",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "list": false,
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 200
              },
              "chunk_size": {
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data, DataFrame\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data or DataFrame\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = CharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separator=separator,\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> list[Data]:\n        return self._docs_to_data(self.split_text_base())\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.split_text())\n"
              },
              "data_inputs": {
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "The data with texts to split in chunks.",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "name": "data_inputs",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_separator": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Keep Separator",
                "dynamic": false,
                "info": "Whether to keep the separator in the output chunks and where to place it.",
                "name": "keep_separator",
                "options": [
                  "False",
                  "True",
                  "Start",
                  "End"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "False"
              },
              "separator": {
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "The key to use for the text column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              }
            }
          },
          "type": "SplitText"
        },
        "dragging": false,
        "height": 475,
        "id": "SplitText-fCJsK",
        "measured": {
          "height": 475,
          "width": 320
        },
        "position": {
          "x": 849.7992026245507,
          "y": 539.1701391058226
        },
        "positionAbsolute": {
          "x": 1683.4543896546102,
          "y": 1350.7871623588553
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-Uid9l",
          "node": {
            "description": "## 🐕 2. Retriever Flow\n\nThis flow answers your questions with contextual data retrieved from your vector database.\n\nEnsure run search is toggled to on, clear existing store is off, and you've entered the vector store Id and name from the load data flow.\n\nOpen the **Playground** and ask, \n\n```\nWhat is this document about?\n```\n",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-Uid9l",
        "measured": {
          "height": 324,
          "width": 325
        },
        "position": {
          "x": 113.8468864153366,
          "y": 1375.8160292285818
        },
        "positionAbsolute": {
          "x": 374.388314931542,
          "y": 486.18094072679895
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 324
        },
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "note-wLDln",
          "node": {
            "description": "## 📖 README\n\nLoad your data into a vector database with the 📚 **Load Data** flow, and then use your data as chat context with the 🐕 **Retriever** flow.\n\n**🚨 Add your NearAI credentials as a global variable to easily add it to all of the NearAI components in this flow.** \n\n**Quick start**\n1. Run the 📚 **Load Data** flow.\n2. Run the 🐕 **Retriever** flow.\n\n**Next steps** \n\n- Experiment by changing the prompt and the loaded data to see how the bot's responses change. \n\nFor more info, see the [Langflow docs](https://docs.langflow.org/starter-projects-vector-store-rag).",
            "display_name": "Read Me",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-wLDln",
        "measured": {
          "height": 324,
          "width": 325
        },
        "position": {
          "x": -247.0003417844148,
          "y": 947.5061664449815
        },
        "positionAbsolute": {
          "x": 94.28986613312418,
          "y": 907.6428043837066
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 324
        },
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-Srsio",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatOutput-Srsio",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 2284.932733905219,
          "y": 1365.4309677452034
        },
        "positionAbsolute": {
          "x": 2734.385670401691,
          "y": 810.6079786425926
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-Csp9A",
          "node": {
            "description": "## 📚 1. Load Data Flow\n\nRun this first! Load data from a local file(s) and embed it into the vector database.\n\nSelect a vector store Id and name or create new ones. \n\nClick ▶️ **Run component** on the **Near Vector DB** component to load your data.\n\nUse the vector store Id output in the retriever flow to query this new vector store.",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-Csp9A",
        "measured": {
          "height": 324,
          "width": 325
        },
        "position": {
          "x": 106.55140827641355,
          "y": 539.2998741957746
        },
        "positionAbsolute": {
          "x": 955.3277857006676,
          "y": 1552.171191793604
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 324
        },
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "File-ANot7",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Load a file to be used in your project.",
            "display_name": "File",
            "documentation": "",
            "edited": false,
            "field_order": [
              "path",
              "silent_errors",
              "use_multithreading",
              "concurrency_multithreading"
            ],
            "frozen": false,
            "icon": "file-text",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "method": "load_files",
                "name": "data",
                "required_inputs": [],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "load_dataframe",
                "name": "dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "load_message",
                "name": "message",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data import BaseFileComponent\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom langflow.io import BoolInput, IntInput\nfrom langflow.schema import Data\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"Handles loading and processing of individual or zipped text files.\n\n    This component supports processing multiple valid files within a zip archive,\n    resolving paths, validating file types, and optionally using multithreading for processing.\n    \"\"\"\n\n    display_name = \"File\"\n    description = \"Load a file to be used in your project.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    VALID_EXTENSIONS = TEXT_FILE_TYPES\n\n    inputs = [\n        *BaseFileComponent._base_inputs,\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent._base_outputs,\n    ]\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Processes files either sequentially or in parallel, depending on concurrency settings.\n\n        Args:\n            file_list (list[BaseFileComponent.BaseFile]): List of files to process.\n\n        Returns:\n            list[BaseFileComponent.BaseFile]: Updated list of files with merged data.\n        \"\"\"\n\n        def process_file(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            \"\"\"Processes a single file and returns its Data object.\"\"\"\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                msg = f\"File not found: {file_path}. Error: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                msg = f\"Unexpected error processing {file_path}: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        concurrency = 1 if not self.use_multithreading else max(1, self.concurrency_multithreading)\n        file_count = len(file_list)\n\n        parallel_processing_threshold = 2\n        if concurrency < parallel_processing_threshold or file_count < parallel_processing_threshold:\n            if file_count > 1:\n                self.log(f\"Processing {file_count} files sequentially.\")\n            processed_data = [process_file(str(file.path), silent_errors=self.silent_errors) for file in file_list]\n        else:\n            self.log(f\"Starting parallel processing of {file_count} files with concurrency: {concurrency}.\")\n            file_paths = [str(file.path) for file in file_list]\n            processed_data = parallel_load_data(\n                file_paths,\n                silent_errors=self.silent_errors,\n                load_function=process_file,\n                max_concurrency=concurrency,\n            )\n\n        # Use rollup_basefile_data to merge processed data with BaseFile objects\n        return self.rollup_data(file_list, processed_data)\n"
              },
              "concurrency_multithreading": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Processing Concurrency",
                "dynamic": false,
                "info": "When multiple files are being processed, the number of files to process concurrently.",
                "list": false,
                "name": "concurrency_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "delete_server_file_after_processing": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Delete Server File After Processing",
                "dynamic": false,
                "info": "If true, the Server File Path will be deleted after processing.",
                "list": false,
                "name": "delete_server_file_after_processing",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "file_path": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "Server File Path",
                "dynamic": false,
                "info": "Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.",
                "input_types": [
                  "Data",
                  "Message"
                ],
                "list": true,
                "name": "file_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_unspecified_files": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unspecified Files",
                "dynamic": false,
                "info": "If true, Data with no 'file_path' property will be ignored.",
                "list": false,
                "name": "ignore_unspecified_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ignore_unsupported_extensions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unsupported Extensions",
                "dynamic": false,
                "info": "If true, files with unsupported extensions will not be processed.",
                "list": false,
                "name": "ignore_unsupported_extensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "zip",
                  "tar",
                  "tgz",
                  "bz2",
                  "gz"
                ],
                "file_path": [
                  "7f2c7441-40b7-467f-b371-651e7f3aa3f8/147dbefd-dcbb-4123-8653-c07ecf4c7529.txt"
                ],
                "info": "Supported file extensions: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx; optionally bundled in file extensions: zip, tar, tgz, bz2, gz",
                "list": true,
                "name": "path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "separator": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "Specify the separator to use between multiple outputs in Message format.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n\n"
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "[Deprecated] Use Multithreading",
                "dynamic": false,
                "info": "Set 'Processing Concurrency' greater than 1 to enable multithreading.",
                "list": false,
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "type": "File"
        },
        "dragging": false,
        "height": 367,
        "id": "File-ANot7",
        "measured": {
          "height": 367,
          "width": 320
        },
        "position": {
          "x": 482.94611782392576,
          "y": 541.6079160217419
        },
        "positionAbsolute": {
          "x": 1318.9043936921921,
          "y": 1484.0151419511485
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "parser-VFDaF",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "parser",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    name = \"parser\"\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Text: {text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "parser"
        },
        "dragging": false,
        "id": "parser-VFDaF",
        "measured": {
          "height": 393,
          "width": 320
        },
        "position": {
          "x": 1207.5087095179395,
          "y": 1371.1303583060337
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "description": "Generates text using NearAI LLMs.",
          "display_name": "NearAI",
          "id": "NearAIModel-nDRyQ",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using NearAI LLMs.",
            "display_name": "NearAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "nearai_api_base",
              "near_credentials",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "NearAI",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "near_credentials"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom langchain_openai import ChatOpenAI\nfrom openai import OpenAI\nfrom pydantic import SecretStr\nfrom typing_extensions import override\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import (\n    BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n)\n\n\nclass NearAIModelComponent(LCModelComponent):\n    display_name = \"NearAI\"\n    description = \"Generates text using NearAI LLMs.\"\n    icon = \"NearAI\"\n    name = \"NearAIModel\"\n\n    nearai_api_base = \"https://api.near.ai/v1\"\n\n    _openai_models = []\n    _model_display_map = {}\n    default_credentials = \"\"\n\n    \n    @override\n    def update_build_config(cls, build_config: dict, field_value: str, field_name: str | None = None):\n        try:\n            credentials_str = SecretStr(cls.near_credentials).get_secret_value()\n            credentials_json = json.loads(credentials_str)\n            api_key = credentials_json[\"auth\"]\n        except Exception as e:\n            print(f\"[update_build_config] Failed to get api_key: {e}\")\n            api_key = None\n    \n        if field_name in {\"nearai_api_base\", \"model_name\"}:\n            models = cls.fetch_openai_models(api_key)\n            cls._model_display_map = {\n                cls.format_model_display_name(m): m for m in models\n            }\n            cls._openai_models = models  # ✅ Ensure this is updated!\n            build_config[\"model_name\"][\"options\"] = list(cls._model_display_map.keys())\n    \n        return build_config\n\n\n    @classmethod\n    def format_model_display_name(cls, model_name: str) -> str:\n        if \"::\" in model_name:\n            provider, full_path = model_name.split(\"::\", 1)\n            short_name = full_path.split(\"/\")[-1]\n            return f\"{provider} - {short_name}\"\n        return model_name\n\n    @classmethod\n    def fetch_openai_models(cls, api_key=None, base_url=None):\n        try:\n            if not api_key:\n                print(\"[fetch_openai_models] No API key provided.\")\n                return cls._openai_models\n    \n            if not base_url:\n                base_url = cls.nearai_api_base\n    \n            client = OpenAI(api_key=api_key, base_url=base_url)\n            response = client.models.list()\n    \n            model_ids = [model.id for model in response.data]\n    \n            if model_ids:\n                cls._openai_models = model_ids\n                cls._model_display_map = {\n                    cls.format_model_display_name(m): m for m in model_ids\n                }\n    \n            return cls._openai_models\n        except Exception as e:\n            print(f\"[fetch_openai_models] Error: {e}\")\n            return cls._openai_models\n\n\n    \n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"Maximum tokens to generate.\",\n            range_spec=RangeSpec(min=0, max=128000)\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional kwargs for the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"Force JSON output.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name 📏\",\n            advanced=False,\n            options=[],\n            real_time_refresh=True,\n            refresh_button=True\n        ),\n        StrInput(\n            name=\"nearai_api_base\",\n            display_name=\"NearAI API Base\",\n            advanced=True,\n            info=\"Base URL of the NearAI API.\",\n            value=nearai_api_base,\n        ),\n        SecretStrInput(\n            name=\"near_credentials\",\n            display_name=\"NEAR Credentials\",\n            info=\"Credential JSON (must include `auth.api_key`).\",\n            advanced=False,\n            required=True,\n            value=default_credentials,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            advanced=True,\n            info=\"Controls reproducibility.\",\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            advanced=True,\n            info=\"Retry attempts for generation.\",\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            advanced=True,\n            info=\"Request timeout in seconds.\",\n            value=700,\n        ),\n    ]\n\n\n    def get_credentials_api_key(self):\n        if not hasattr(self, \"near_credentials\") or not self.near_credentials:\n            return None\n        try:\n            credentials_str = SecretStr(self.near_credentials).get_secret_value()\n            credentials_json = json.loads(credentials_str)\n    \n            # ✅ Correct extraction o\n            return json.dumps(credentials_json[\"auth\"])\n        except Exception as e:\n            print(f\"[get_credentials_api_key] Failed: {e}\")\n            return None\n\n    def build_model(self) -> LanguageModel:\n        api_key = self.get_credentials_api_key()\n    \n        # Ensure we have models\n        if not self.__class__._openai_models:\n            print(\"[build_model] _openai_models is empty — calling fetch_openai_models() manually...\")\n            self.__class__.fetch_openai_models(api_key=api_key, base_url=self.nearai_api_base)\n    \n        model_name = self.model_name\n        print(f\"[build_model] self.model_name (dropdown selected): {model_name}\")\n    \n        if not self.__class__._model_display_map:\n            print(\"[build_model] _model_display_map is empty. Rebuilding from _openai_models...\")\n            print(f\"[build_model] _openai_models: {self.__class__._openai_models}\")\n            self.__class__._model_display_map = {\n                self.__class__.format_model_display_name(m): m\n                for m in self.__class__._openai_models\n            }\n    \n        print(f\"[build_model] available model keys: {list(self.__class__._model_display_map.keys())}\")\n    \n        resolved = self.__class__._model_display_map.get(model_name, model_name)\n        print(f\"[build_model] resolved model_name: {resolved}\")\n        if resolved == model_name:\n            print(f\"[build_model] WARNING: '{model_name}' was not mapped — using it directly.\")\n    \n        return ChatOpenAI(\n            model=resolved,\n            api_key=api_key,\n            base_url=self.nearai_api_base,\n            temperature=self.temperature or 0.1,\n            max_tokens=self.max_tokens or None,\n            model_kwargs=self.model_kwargs or {},\n            max_retries=self.max_retries,\n            request_timeout=self.timeout,\n        ).bind(response_format={\"type\": \"json_object\"}) if self.json_mode else ChatOpenAI(\n            model=resolved,\n            api_key=api_key,\n            base_url=self.nearai_api_base,\n            temperature=self.temperature or 0.1,\n            max_tokens=self.max_tokens or None,\n            model_kwargs=self.model_kwargs or {},\n            max_retries=self.max_retries,\n            request_timeout=self.timeout,\n        )\n\n\n\n    def _get_exception_message(self, e: Exception):\n        try:\n            from openai import BadRequestError\n            if isinstance(e, BadRequestError):\n                return e.body.get(\"message\", \"Unknown OpenAI error\")\n        except ImportError:\n            return None\n        return str(e)"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "Force JSON output.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "Retry attempts for generation.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional kwargs for the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name 📏",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "model_name",
                "options": [],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "fireworks - llama-v3-70b-instruct"
              },
              "near_credentials": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "NEAR Credentials",
                "dynamic": false,
                "info": "Credential JSON (must include `auth.api_key`).",
                "input_types": [],
                "load_from_db": true,
                "name": "near_credentials",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "NEAR"
              },
              "nearai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "NearAI API Base",
                "dynamic": false,
                "info": "Base URL of the NearAI API.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "nearai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://api.near.ai/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "Controls reproducibility.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Request timeout in seconds.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "NearAIModel"
        },
        "dragging": false,
        "id": "NearAIModel-nDRyQ",
        "measured": {
          "height": 611,
          "width": 320
        },
        "position": {
          "x": 1931.0233164736296,
          "y": 1364.3720306055905
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "NearVectorDB-m7loS",
          "node": {
            "base_classes": [
              "Data",
              "Text"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Upload files to NEAR AI and optionally perform a search",
            "display_name": "NEAR Vector DB",
            "documentation": "",
            "edited": false,
            "field_order": [
              "near_credentials",
              "store_name",
              "provided_vector_store_id",
              "clear_existing_store",
              "search_query",
              "number_of_results",
              "search_type",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "score_threshold",
              "search_filter",
              "run_search"
            ],
            "frozen": false,
            "icon": "NearAI",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Vector Store Info",
                "method": "build_store",
                "name": "vector_store_data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Vector Store ID",
                "method": "get_vector_store_id",
                "name": "vector_store_id",
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clear_existing_store": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Clear Existing Store",
                "dynamic": false,
                "info": "If true and a vector store ID is provided, will delete and recreate it.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "clear_existing_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nimport json\nimport requests\nimport openai\nfrom pydantic import SecretStr\nfrom langchain.schema import Document\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.custom import Component\nfrom langflow.inputs import (\n    SecretStrInput,\n    StrInput,\n    IntInput,\n    FloatInput,\n    NestedDictInput,\n    DropdownInput,\n    BoolInput,\n)\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.helpers import docs_to_data\n\n\nclass NearVectorStoreComponent(Component):\n    display_name: str = \"NEAR Vector DB\"\n    description: str = \"Upload files to NEAR AI and optionally perform a search\"\n    name = \"NearVectorDB\"\n    icon: str = \"NearAI\"\n\n    nearai_api_base = \"https://api.near.ai/v1\"\n    default_credentials = \"\"\n    vector_store_id: str = None\n\n    inputs = [\n        SecretStrInput(\n            name=\"near_credentials\",\n            display_name=\"NEAR credentials\",\n            info=\"NEAR AI credentials as JSON\",\n            required=True,\n        ),\n        StrInput(\n            name=\"store_name\",\n            display_name=\"Vector Store Name\",\n            value=\"langflow-store\",\n            required=False,\n        ),\n        StrInput(\n            name=\"provided_vector_store_id\",\n            display_name=\"Vector Store ID\",\n            required=False,\n            advanced=False,\n            info=\"If provided, will use this existing vector store instead of creating a new one.\",\n        ),\n        BoolInput(\n            name=\"clear_existing_store\",\n            display_name=\"Clear Existing Store\",\n            value=False,\n            advanced=False,\n            info=\"If true and a vector store ID is provided, will delete and recreate it.\",\n        ),\n        StrInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            required=False,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            value=4,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"similarity\", \"similarity_score_threshold\", \"mmr\"],\n            value=\"similarity\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        FloatInput(\n            name=\"score_threshold\",\n            display_name=\"Score Threshold\",\n            value=0.0,\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"run_search\",\n            display_name=\"Run Search\",\n            value=False,\n            advanced=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Vector Store Info\",\n            name=\"vector_store_data\",\n            info=\"Vector store ID and upload result.\",\n            method=\"build_store\",\n        ),\n        Output(\n            display_name=\"Vector Store ID\",\n            name=\"vector_store_id\",\n            info=\"Just the vector store ID.\",\n            method=\"get_vector_store_id\",\n        ),\n        Output(\n            display_name=\"Search Results\",\n            name=\"search_results\",\n            info=\"List of matching documents from the vector store.\",\n            method=\"search_documents\",\n        ),\n    ]\n\n    def __init__(self, **data):\n        super().__init__(**data)\n\n    def get_vector_store_id(self) -> str:\n        if not self.vector_store_id:\n            self.build_store()\n        return self.vector_store_id\n\n    def build_store(self) -> Data:\n        provided_id = getattr(self, \"provided_vector_store_id\", \"\").strip()\n        clear_existing = getattr(self, \"clear_existing_store\", False)\n        store_name = getattr(self, \"store_name\", \"langflow-store\")\n    \n        credentials_str = SecretStr(self.near_credentials).get_secret_value()\n        credentials = json.loads(credentials_str)\n        auth = credentials.get(\"auth\")\n        if not auth:\n            raise ValueError(\"Invalid NEAR credentials provided.\")\n        api_key = json.dumps(auth)\n    \n        headers_json = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n    \n        # --- CASE 1: Run search only, skip ingestion ---\n        if getattr(self, \"run_search\", False) and provided_id and not clear_existing:\n            print(f\"[SEARCH-ONLY] Skipping ingestion, using existing vector store: {provided_id}\")\n            self.vector_store_id = provided_id\n            return {\n                \"vector_store_id\": self.vector_store_id,\n                \"status\": \"search_only_used_existing_store\",\n                \"store_name\": store_name,\n                \"uploaded_file_ids\": [],\n            }\n    \n        # --- CASE 2: Clear files from existing store without deleting the store ---\n        if provided_id and clear_existing:\n            print(f\"[CLEAR] Detaching all files from vector store: {provided_id}\")\n            self.vector_store_id = provided_id\n    \n            # Step 1: List attached files\n            list_url = f\"{self.nearai_api_base}/vector_stores/{provided_id}/files\"\n            list_response = requests.get(list_url, headers=headers_json)\n    \n            if list_response.status_code != 200:\n                raise ValueError(f\"[CLEAR ERROR] Failed to list files: {list_response.status_code} - {list_response.text}\")\n    \n            list_data = list_response.json()\n            file_list = list_data.get(\"data\", [])\n    \n            print(f\"[CLEAR] Found {len(file_list)} files to detach.\")\n    \n            # Step 2: Detach each file\n            for file_info in file_list:\n                file_id = file_info.get(\"id\")  # <- this is the correct field per API docs\n                if not file_id:\n                    print(f\"[WARN] Skipping invalid file info: {file_info}\")\n                    continue\n    \n                detach_url = f\"{self.nearai_api_base}/vector_stores/{provided_id}/files/{file_id}\"\n                detach_response = requests.delete(detach_url, headers=headers_json)\n    \n                if detach_response.status_code not in (200, 204):\n                    print(f\"[WARN] Failed to detach file {file_id}: {detach_response.status_code} - {detach_response.text}\")\n                else:\n                    print(f\"[DETACH] Successfully detached file {file_id}\")\n    \n        # --- CASE 3: Provided ID but not clearing, validate and fallback to create ---\n        elif provided_id:\n            print(f\"[USE EXISTING] Validating existing vector store ID: {provided_id}\")\n            check_url = f\"{self.nearai_api_base}/vector_stores/{provided_id}\"\n            check_response = requests.get(check_url, headers=headers_json)\n    \n            if check_response.status_code == 200:\n                self.vector_store_id = provided_id\n                print(f\"[USE EXISTING] Using verified vector store ID: {self.vector_store_id}\")\n            elif check_response.status_code == 404:\n                print(f\"[NOT FOUND] Vector store ID {provided_id} not found. Creating new store: {store_name}\")\n                create_url = f\"{self.nearai_api_base}/vector_stores\"\n                create_response = requests.post(create_url, headers=headers_json, json={\"name\": store_name})\n                create_response.raise_for_status()\n                self.vector_store_id = create_response.json()[\"id\"]\n                print(f\"[CREATE] Created new vector store ID: {self.vector_store_id}\")\n            else:\n                raise ValueError(f\"Error validating vector store {provided_id}: {check_response.status_code} - {check_response.text}\")\n    \n        # --- CASE 4: No ID provided, create new store ---\n        elif not provided_id:\n            print(f\"[CREATE] No vector store ID provided, creating a new one.\")\n            create_url = f\"{self.nearai_api_base}/vector_stores\"\n            create_response = requests.post(create_url, headers=headers_json, json={\"name\": store_name})\n            create_response.raise_for_status()\n            self.vector_store_id = create_response.json()[\"id\"]\n            print(f\"[CREATE] Created vector store ID: {self.vector_store_id}\")\n    \n        # --- Check if ingestion data is present ---\n        if not hasattr(self, \"ingest_data\") or not self.ingest_data:\n            raise ValueError(\"No data provided for ingestion.\")\n    \n        # --- Upload and attach files ---\n        file_ids = []\n        for i, data_obj in enumerate(self.ingest_data):\n            text = data_obj.data.get(\"text\", \"\")\n            metadata = data_obj.data.get(\"metadata\", {})\n            if not text.strip():\n                print(f\"[SKIP] Chunk {i} is empty.\")\n                continue\n    \n            file_type = metadata.get(\"file_type\", \"txt\").lower()\n            ext = {\n                \"pdf\": \".pdf\",\n                \"md\": \".md\",\n                \"markdown\": \".md\"\n            }.get(file_type, \".txt\")\n    \n            mime_type = {\n                \".pdf\": \"application/pdf\",\n                \".md\": \"text/markdown\",\n                \".txt\": \"text/plain\"\n            }.get(ext, \"text/plain\")\n    \n            print(f\"[UPLOAD] Uploading file_{i}{ext} to /v1/files as {mime_type}\")\n    \n            files = {\n                \"file\": (f\"file_{i}{ext}\", text.encode(\"utf-8\"), mime_type),\n                \"purpose\": (None, \"assistants\")\n            }\n    \n            upload_response = requests.post(\n                f\"{self.nearai_api_base}/files\",\n                headers={\"Authorization\": f\"Bearer {api_key}\"},\n                files=files\n            )\n    \n            if upload_response.status_code != 200:\n                print(f\"[ERROR] File upload failed for file_{i}{ext}\")\n                print(f\"[ERROR] Status: {upload_response.status_code}\")\n                print(f\"[ERROR] Response: {upload_response.text}\")\n                continue\n    \n            file_id = upload_response.json().get(\"id\")\n            if not file_id:\n                print(f\"[ERROR] No file_id returned for file_{i}{ext}\")\n                continue\n    \n            file_ids.append(file_id)\n            print(f\"[UPLOAD] Uploaded and received file_id: {file_id}\")\n    \n            attach_url = f\"{self.nearai_api_base}/vector_stores/{self.vector_store_id}/files\"\n            attach_response = requests.post(\n                attach_url,\n                headers=headers_json,\n                json={\"file_id\": file_id}\n            )\n    \n            if attach_response.status_code != 200:\n                print(f\"[ERROR] Failed to attach file_id {file_id} to vector store.\")\n                print(f\"[ERROR] Response: {attach_response.text}\")\n                continue\n    \n            print(f\"[LINK] Linked file_id {file_id} to vector store {self.vector_store_id}\")\n    \n        if not file_ids:\n            raise ValueError(\"No files were successfully uploaded or linked.\")\n    \n        return {\n            \"vector_store_id\": self.vector_store_id,\n            \"status\": \"created_and_uploaded\" if not provided_id else \"uploaded_to_existing\",\n            \"store_name\": store_name,\n            \"uploaded_file_ids\": file_ids\n        }\n\n    def search_documents(self) -> list[Data]:\n        if not getattr(self, \"run_search\", False):\n            print(\"[INFO] Search disabled (run_search=False). Skipping search.\")\n            return []\n    \n        # Set vector_store_id if provided\n        provided_id = getattr(self, \"provided_vector_store_id\", \"\").strip()\n        if provided_id:\n            self.vector_store_id = provided_id\n            print(f\"[INFO] Using provided vector store ID: {self.vector_store_id}\")\n        elif not self.vector_store_id:\n            print(\"[INFO] No vector store ID provided. Attempting to build a new one...\")\n            store_data = self.build_store()\n            self.vector_store_id = store_data[\"vector_store_id\"]\n    \n        if not self.vector_store_id:\n            raise ValueError(\"No vector store ID available for search.\")\n    \n        print(f\"[SEARCH] Running search against vector_store_id = {self.vector_store_id}\")\n    \n        # Prepare API key and client\n        credentials_str = SecretStr(self.near_credentials).get_secret_value()\n        credentials = json.loads(credentials_str)\n        auth = credentials.get(\"auth\")\n        if not auth:\n            raise ValueError(\"Missing 'auth' field in NEAR credentials.\")\n        api_key = json.dumps(auth)\n    \n        headers = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n    \n        search_args = {\n            \"query\": getattr(self, \"search_query\", \"\"),\n            \"search_type\": getattr(self, \"search_type\", \"similarity\"),\n            \"k\": getattr(self, \"number_of_results\", 4),\n        }\n    \n        if self.score_threshold > 0:\n            search_args[\"score_threshold\"] = self.score_threshold\n    \n        if getattr(self, \"search_filter\", None):\n            search_args[\"filter\"] = self.search_filter\n    \n        print(f\"[SEARCH] Search Payload:\\n{json.dumps(search_args, indent=2)}\")\n    \n        url = f\"{self.nearai_api_base}/vector_stores/{self.vector_store_id}/search\"\n        response = requests.post(url, headers=headers, json=search_args)\n    \n        print(f\"[SEARCH RESPONSE] Status: {response.status_code}\")\n        print(f\"[SEARCH RESPONSE] Body:\\n{response.text}\")\n    \n        if response.status_code == 404:\n            raise ValueError(f\"Vector store not found at {url}. ID: {self.vector_store_id}\")\n    \n        response.raise_for_status()\n    \n        resp_json = response.json()\n        print(f\"[SEARCH RESPONSE] JSON:\\n{json.dumps(resp_json, indent=2)}\")\n        \n        if isinstance(resp_json, list):\n            docs = [\n                Document(\n                    page_content=item.get(\"chunk_text\", \"\"),\n                    metadata={\n                        \"file_id\": item.get(\"file_id\"),\n                        \"distance\": item.get(\"distance\"),\n                    },\n                )\n                for item in resp_json\n            ]\n        elif isinstance(resp_json, dict) and \"documents\" in resp_json:\n            docs = resp_json[\"documents\"]  # Should already be Document-like\n        else:\n            print(f\"[ERROR] Unexpected search response format: {resp_json}\")\n            raise ValueError(\"Unexpected format in NEAR AI search response.\")\n        \n        combined_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n        return Data(data={\"text\": combined_text})\n\n\n"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "near_credentials": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "NEAR credentials",
                "dynamic": false,
                "info": "NEAR AI credentials as JSON",
                "input_types": [],
                "load_from_db": true,
                "name": "near_credentials",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "NEAR"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "provided_vector_store_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Vector Store ID",
                "dynamic": false,
                "info": "If provided, will use this existing vector store instead of creating a new one.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "provided_vector_store_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "vs_5ed930f62124445ab71aab2f"
              },
              "run_search": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Run Search",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "run_search",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Score Threshold",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_filter": {
                "_input_type": "NestedDictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "NestedDict",
                "value": {}
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Type",
                "dynamic": false,
                "info": "",
                "name": "search_type",
                "options": [
                  "similarity",
                  "similarity_score_threshold",
                  "mmr"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "similarity"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "store_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Vector Store Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "store_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "aaron"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "NearVectorDB"
        },
        "dragging": false,
        "id": "NearVectorDB-m7loS",
        "measured": {
          "height": 719,
          "width": 320
        },
        "position": {
          "x": 1216.2120227766115,
          "y": 534.1302379844051
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "NearVectorDB-eKQKI",
          "node": {
            "base_classes": [
              "Data",
              "Text"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Upload files to NEAR AI and optionally perform a search",
            "display_name": "NEAR Vector DB",
            "documentation": "",
            "edited": false,
            "field_order": [
              "near_credentials",
              "store_name",
              "provided_vector_store_id",
              "clear_existing_store",
              "search_query",
              "number_of_results",
              "search_type",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "score_threshold",
              "search_filter",
              "run_search"
            ],
            "frozen": false,
            "icon": "NearAI",
            "legacy": false,
            "lf_version": "1.3.2",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Vector Store Info",
                "method": "build_store",
                "name": "vector_store_data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Vector Store ID",
                "method": "get_vector_store_id",
                "name": "vector_store_id",
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clear_existing_store": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Clear Existing Store",
                "dynamic": false,
                "info": "If true and a vector store ID is provided, will delete and recreate it.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "clear_existing_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\nimport json\nimport requests\nimport openai\nfrom pydantic import SecretStr\nfrom langchain.schema import Document\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.custom import Component\nfrom langflow.inputs import (\n    SecretStrInput,\n    StrInput,\n    IntInput,\n    FloatInput,\n    NestedDictInput,\n    DropdownInput,\n    BoolInput,\n)\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.helpers import docs_to_data\n\n\nclass NearVectorStoreComponent(Component):\n    display_name: str = \"NEAR Vector DB\"\n    description: str = \"Upload files to NEAR AI and optionally perform a search\"\n    name = \"NearVectorDB\"\n    icon: str = \"NearAI\"\n\n    nearai_api_base = \"https://api.near.ai/v1\"\n    default_credentials = \"\"\n    vector_store_id: str = None\n\n    inputs = [\n        SecretStrInput(\n            name=\"near_credentials\",\n            display_name=\"NEAR credentials\",\n            info=\"NEAR AI credentials as JSON\",\n            required=True,\n        ),\n        StrInput(\n            name=\"store_name\",\n            display_name=\"Vector Store Name\",\n            value=\"langflow-store\",\n            required=False,\n        ),\n        StrInput(\n            name=\"provided_vector_store_id\",\n            display_name=\"Vector Store ID\",\n            required=False,\n            advanced=False,\n            info=\"If provided, will use this existing vector store instead of creating a new one.\",\n        ),\n        BoolInput(\n            name=\"clear_existing_store\",\n            display_name=\"Clear Existing Store\",\n            value=False,\n            advanced=False,\n            info=\"If true and a vector store ID is provided, will delete and recreate it.\",\n        ),\n        StrInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            required=False,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            value=4,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"similarity\", \"similarity_score_threshold\", \"mmr\"],\n            value=\"similarity\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        FloatInput(\n            name=\"score_threshold\",\n            display_name=\"Score Threshold\",\n            value=0.0,\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"run_search\",\n            display_name=\"Run Search\",\n            value=False,\n            advanced=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Vector Store Info\",\n            name=\"vector_store_data\",\n            info=\"Vector store ID and upload result.\",\n            method=\"build_store\",\n        ),\n        Output(\n            display_name=\"Vector Store ID\",\n            name=\"vector_store_id\",\n            info=\"Just the vector store ID.\",\n            method=\"get_vector_store_id\",\n        ),\n        Output(\n            display_name=\"Search Results\",\n            name=\"search_results\",\n            info=\"List of matching documents from the vector store.\",\n            method=\"search_documents\",\n        ),\n    ]\n\n    def __init__(self, **data):\n        super().__init__(**data)\n\n    def get_vector_store_id(self) -> str:\n        if not self.vector_store_id:\n            self.build_store()\n        return self.vector_store_id\n\n    def build_store(self) -> Data:\n        provided_id = getattr(self, \"provided_vector_store_id\", \"\").strip()\n        clear_existing = getattr(self, \"clear_existing_store\", False)\n        store_name = getattr(self, \"store_name\", \"langflow-store\")\n    \n        credentials_str = SecretStr(self.near_credentials).get_secret_value()\n        credentials = json.loads(credentials_str)\n        auth = credentials.get(\"auth\")\n        if not auth:\n            raise ValueError(\"Invalid NEAR credentials provided.\")\n        api_key = json.dumps(auth)\n    \n        headers_json = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n    \n        # --- CASE 1: Run search only, skip ingestion ---\n        if getattr(self, \"run_search\", False) and provided_id and not clear_existing:\n            print(f\"[SEARCH-ONLY] Skipping ingestion, using existing vector store: {provided_id}\")\n            self.vector_store_id = provided_id\n            return {\n                \"vector_store_id\": self.vector_store_id,\n                \"status\": \"search_only_used_existing_store\",\n                \"store_name\": store_name,\n                \"uploaded_file_ids\": [],\n            }\n    \n        # --- CASE 2: Clear files from existing store without deleting the store ---\n        if provided_id and clear_existing:\n            print(f\"[CLEAR] Detaching all files from vector store: {provided_id}\")\n            self.vector_store_id = provided_id\n    \n            # Step 1: List attached files\n            list_url = f\"{self.nearai_api_base}/vector_stores/{provided_id}/files\"\n            list_response = requests.get(list_url, headers=headers_json)\n    \n            if list_response.status_code != 200:\n                raise ValueError(f\"[CLEAR ERROR] Failed to list files: {list_response.status_code} - {list_response.text}\")\n    \n            list_data = list_response.json()\n            file_list = list_data.get(\"data\", [])\n    \n            print(f\"[CLEAR] Found {len(file_list)} files to detach.\")\n    \n            # Step 2: Detach each file\n            for file_info in file_list:\n                file_id = file_info.get(\"id\")  # <- this is the correct field per API docs\n                if not file_id:\n                    print(f\"[WARN] Skipping invalid file info: {file_info}\")\n                    continue\n    \n                detach_url = f\"{self.nearai_api_base}/vector_stores/{provided_id}/files/{file_id}\"\n                detach_response = requests.delete(detach_url, headers=headers_json)\n    \n                if detach_response.status_code not in (200, 204):\n                    print(f\"[WARN] Failed to detach file {file_id}: {detach_response.status_code} - {detach_response.text}\")\n                else:\n                    print(f\"[DETACH] Successfully detached file {file_id}\")\n    \n        # --- CASE 3: Provided ID but not clearing, validate and fallback to create ---\n        elif provided_id:\n            print(f\"[USE EXISTING] Validating existing vector store ID: {provided_id}\")\n            check_url = f\"{self.nearai_api_base}/vector_stores/{provided_id}\"\n            check_response = requests.get(check_url, headers=headers_json)\n    \n            if check_response.status_code == 200:\n                self.vector_store_id = provided_id\n                print(f\"[USE EXISTING] Using verified vector store ID: {self.vector_store_id}\")\n            elif check_response.status_code == 404:\n                print(f\"[NOT FOUND] Vector store ID {provided_id} not found. Creating new store: {store_name}\")\n                create_url = f\"{self.nearai_api_base}/vector_stores\"\n                create_response = requests.post(create_url, headers=headers_json, json={\"name\": store_name})\n                create_response.raise_for_status()\n                self.vector_store_id = create_response.json()[\"id\"]\n                print(f\"[CREATE] Created new vector store ID: {self.vector_store_id}\")\n            else:\n                raise ValueError(f\"Error validating vector store {provided_id}: {check_response.status_code} - {check_response.text}\")\n    \n        # --- CASE 4: No ID provided, create new store ---\n        elif not provided_id:\n            print(f\"[CREATE] No vector store ID provided, creating a new one.\")\n            create_url = f\"{self.nearai_api_base}/vector_stores\"\n            create_response = requests.post(create_url, headers=headers_json, json={\"name\": store_name})\n            create_response.raise_for_status()\n            self.vector_store_id = create_response.json()[\"id\"]\n            print(f\"[CREATE] Created vector store ID: {self.vector_store_id}\")\n    \n        # --- Check if ingestion data is present ---\n        if not hasattr(self, \"ingest_data\") or not self.ingest_data:\n            raise ValueError(\"No data provided for ingestion.\")\n    \n        # --- Upload and attach files ---\n        file_ids = []\n        for i, data_obj in enumerate(self.ingest_data):\n            text = data_obj.data.get(\"text\", \"\")\n            metadata = data_obj.data.get(\"metadata\", {})\n            if not text.strip():\n                print(f\"[SKIP] Chunk {i} is empty.\")\n                continue\n    \n            file_type = metadata.get(\"file_type\", \"txt\").lower()\n            ext = {\n                \"pdf\": \".pdf\",\n                \"md\": \".md\",\n                \"markdown\": \".md\"\n            }.get(file_type, \".txt\")\n    \n            mime_type = {\n                \".pdf\": \"application/pdf\",\n                \".md\": \"text/markdown\",\n                \".txt\": \"text/plain\"\n            }.get(ext, \"text/plain\")\n    \n            print(f\"[UPLOAD] Uploading file_{i}{ext} to /v1/files as {mime_type}\")\n    \n            files = {\n                \"file\": (f\"file_{i}{ext}\", text.encode(\"utf-8\"), mime_type),\n                \"purpose\": (None, \"assistants\")\n            }\n    \n            upload_response = requests.post(\n                f\"{self.nearai_api_base}/files\",\n                headers={\"Authorization\": f\"Bearer {api_key}\"},\n                files=files\n            )\n    \n            if upload_response.status_code != 200:\n                print(f\"[ERROR] File upload failed for file_{i}{ext}\")\n                print(f\"[ERROR] Status: {upload_response.status_code}\")\n                print(f\"[ERROR] Response: {upload_response.text}\")\n                continue\n    \n            file_id = upload_response.json().get(\"id\")\n            if not file_id:\n                print(f\"[ERROR] No file_id returned for file_{i}{ext}\")\n                continue\n    \n            file_ids.append(file_id)\n            print(f\"[UPLOAD] Uploaded and received file_id: {file_id}\")\n    \n            attach_url = f\"{self.nearai_api_base}/vector_stores/{self.vector_store_id}/files\"\n            attach_response = requests.post(\n                attach_url,\n                headers=headers_json,\n                json={\"file_id\": file_id}\n            )\n    \n            if attach_response.status_code != 200:\n                print(f\"[ERROR] Failed to attach file_id {file_id} to vector store.\")\n                print(f\"[ERROR] Response: {attach_response.text}\")\n                continue\n    \n            print(f\"[LINK] Linked file_id {file_id} to vector store {self.vector_store_id}\")\n    \n        if not file_ids:\n            raise ValueError(\"No files were successfully uploaded or linked.\")\n    \n        return {\n            \"vector_store_id\": self.vector_store_id,\n            \"status\": \"created_and_uploaded\" if not provided_id else \"uploaded_to_existing\",\n            \"store_name\": store_name,\n            \"uploaded_file_ids\": file_ids\n        }\n\n    def search_documents(self) -> list[Data]:\n        if not getattr(self, \"run_search\", False):\n            print(\"[INFO] Search disabled (run_search=False). Skipping search.\")\n            return []\n    \n        # Set vector_store_id if provided\n        provided_id = getattr(self, \"provided_vector_store_id\", \"\").strip()\n        if provided_id:\n            self.vector_store_id = provided_id\n            print(f\"[INFO] Using provided vector store ID: {self.vector_store_id}\")\n        elif not self.vector_store_id:\n            print(\"[INFO] No vector store ID provided. Attempting to build a new one...\")\n            store_data = self.build_store()\n            self.vector_store_id = store_data[\"vector_store_id\"]\n    \n        if not self.vector_store_id:\n            raise ValueError(\"No vector store ID available for search.\")\n    \n        print(f\"[SEARCH] Running search against vector_store_id = {self.vector_store_id}\")\n    \n        # Prepare API key and client\n        credentials_str = SecretStr(self.near_credentials).get_secret_value()\n        credentials = json.loads(credentials_str)\n        auth = credentials.get(\"auth\")\n        if not auth:\n            raise ValueError(\"Missing 'auth' field in NEAR credentials.\")\n        api_key = json.dumps(auth)\n    \n        headers = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n    \n        search_args = {\n            \"query\": getattr(self, \"search_query\", \"\"),\n            \"search_type\": getattr(self, \"search_type\", \"similarity\"),\n            \"k\": getattr(self, \"number_of_results\", 4),\n        }\n    \n        if self.score_threshold > 0:\n            search_args[\"score_threshold\"] = self.score_threshold\n    \n        if getattr(self, \"search_filter\", None):\n            search_args[\"filter\"] = self.search_filter\n    \n        print(f\"[SEARCH] Search Payload:\\n{json.dumps(search_args, indent=2)}\")\n    \n        url = f\"{self.nearai_api_base}/vector_stores/{self.vector_store_id}/search\"\n        response = requests.post(url, headers=headers, json=search_args)\n    \n        print(f\"[SEARCH RESPONSE] Status: {response.status_code}\")\n        print(f\"[SEARCH RESPONSE] Body:\\n{response.text}\")\n    \n        if response.status_code == 404:\n            raise ValueError(f\"Vector store not found at {url}. ID: {self.vector_store_id}\")\n    \n        response.raise_for_status()\n    \n        resp_json = response.json()\n        print(f\"[SEARCH RESPONSE] JSON:\\n{json.dumps(resp_json, indent=2)}\")\n        \n        if isinstance(resp_json, list):\n            docs = [\n                Document(\n                    page_content=item.get(\"chunk_text\", \"\"),\n                    metadata={\n                        \"file_id\": item.get(\"file_id\"),\n                        \"distance\": item.get(\"distance\"),\n                    },\n                )\n                for item in resp_json\n            ]\n        elif isinstance(resp_json, dict) and \"documents\" in resp_json:\n            docs = resp_json[\"documents\"]  # Should already be Document-like\n        else:\n            print(f\"[ERROR] Unexpected search response format: {resp_json}\")\n            raise ValueError(\"Unexpected format in NEAR AI search response.\")\n        \n        combined_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n        return Data(data={\"text\": combined_text})\n\n\n"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "near_credentials": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "NEAR credentials",
                "dynamic": false,
                "info": "NEAR AI credentials as JSON",
                "input_types": [],
                "load_from_db": true,
                "name": "near_credentials",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "NEAR"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "provided_vector_store_id": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Vector Store ID",
                "dynamic": false,
                "info": "If provided, will use this existing vector store instead of creating a new one.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "provided_vector_store_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "vs_5ed930f62124445ab71aab2f"
              },
              "run_search": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Run Search",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "run_search",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Score Threshold",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_filter": {
                "_input_type": "NestedDictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "NestedDict",
                "value": {}
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Type",
                "dynamic": false,
                "info": "",
                "name": "search_type",
                "options": [
                  "similarity",
                  "similarity_score_threshold",
                  "mmr"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "similarity"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "store_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Vector Store Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "store_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "aaron"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "NearVectorDB"
        },
        "dragging": false,
        "id": "NearVectorDB-eKQKI",
        "measured": {
          "height": 719,
          "width": 320
        },
        "position": {
          "x": 843.2940108134197,
          "y": 1361.0778037035875
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 226.47060112603924,
      "y": -230.03465786281447,
      "zoom": 0.5034320753701682
    }
  },
  "description": "Load your data for chat context with Retrieval Augmented Generation and NearAI vector db.",
  "endpoint_name": null,
  "folder_id": "63a2920d-ad81-49f9-b99f-95452558186f",
  "fs_path": null,
  "gradient": null,
  "icon": null,
  "icon_bg_color": null,
  "id": "0dc468be-780e-46db-9078-2204a8fa9198",
  "is_component": false,
  "locked": false,
  "name": "NearAI Vector Store RAG",
  "tags": [
    "openai",
    "astradb",
    "rag",
    "q-a"
  ],
  "updated_at": "2025-04-19T12:45:49+00:00",
  "user_id": "7f2c7441-40b7-467f-b371-651e7f3aa3f8",
  "webhook": false
}